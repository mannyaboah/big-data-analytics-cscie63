{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HU Extension                     Assignment 05           E63 Big Data Analytics\n",
    "## Emmanuel Aboah\n",
    "### Issued on: Feb 24, 2023                    Due on Saturday by 11:59 AM EST, March 4th, 2023"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1. \n",
    "Use VMWare (Workstation or Fusion) Player to create an Ubuntu22.04 Virtual Machine. If you already have a functioning VM, you are welcome to use it. Demonstrate that by using ssh you can connect from your host machine to your VM. If you are using an EC2 Instance in the AWS Cloud you can use that instance instead. When capturing screenshots of your ssh dialog, please include the date and time of your experiments. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For my solutions I will be using Windows Subsystem Linux (WSL2) and running a single node cluster of kafka using docker-compose.\n",
    "\n",
    "```bash\n",
    "# Ubuntu version\n",
    "(base) manny@LAPTOP-85L1BUVJ:~$ lsb_release -a\n",
    "No LSB modules are available.\n",
    "Distributor ID: Ubuntu\n",
    "Description:    Ubuntu 18.04.6 LTS\n",
    "Release:        18.04\n",
    "Codename:       bionic\n",
    "\n",
    "# Docker version\n",
    "(base) manny@LAPTOP-85L1BUVJ:~$ docker version\n",
    "Client: Docker Engine - Community\n",
    " Cloud integration: v1.0.29\n",
    " Version:           20.10.22\n",
    " API version:       1.41\n",
    " Go version:        go1.18.9\n",
    " Git commit:        3a2c30b\n",
    " Built:             Thu Dec 15 22:28:22 2022\n",
    " OS/Arch:           linux/amd64\n",
    " Context:           default\n",
    " Experimental:      true\n",
    "\n",
    "Server: Docker Desktop\n",
    " Engine:\n",
    "  Version:          20.10.22\n",
    "  API version:      1.41 (minimum version 1.12)\n",
    "  Go version:       go1.18.9\n",
    "  Git commit:       42c8b31\n",
    "  Built:            Thu Dec 15 22:26:14 2022\n",
    "  OS/Arch:          linux/amd64\n",
    "  Experimental:     false\n",
    " containerd:\n",
    "  Version:          1.6.14\n",
    "  GitCommit:        9ba4b250366a5ddde94bb7c9d1def331423aa323\n",
    " runc:\n",
    "  Version:          1.1.4\n",
    "  GitCommit:        v1.1.4-0-g5fd4c4d\n",
    " docker-init:\n",
    "  Version:          0.19.0\n",
    "  GitCommit:        de40ad0\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2. \n",
    "From http://kafka.apache.org, download and install single node Kafka on above VM. You are welcome to try the most recent version 3.4 or somewhat older 3.3.2. Install your Kafka for Scala 2.12.x. Demonstrate that you can start both Zookeeper and Kafka server. Demonstrate that you can start either of them and stop either of them. How will you find out whether Zookeeper is listening on port 2181 and Kafka server on port 9092? You might find appropriate Linux (Ubuntu) commands with Google’s help. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single node kafka cluster running in docker containers.\n",
    "</br>\n",
    "\n",
    "docker-compose.yaml\n",
    "\n",
    "```yaml\n",
    "version: \"3.8\"\n",
    "networks:\n",
    "  hw05-project:\n",
    "    name: hw05-net\n",
    "    driver: bridge\n",
    "services:\n",
    "  #Zookeeper container\n",
    "  zookeeper:\n",
    "    image: confluentinc/cp-zookeeper\n",
    "    hostname: zookeeper\n",
    "    container_name: zookeeper\n",
    "    networks:\n",
    "      - hw05-project\n",
    "    ports:\n",
    "      - \"2181:2181\"\n",
    "    environment:\n",
    "      ZOOKEEPER_CLIENT_PORT: 2181\n",
    "      ZOOKEEPER_TICK_TIME: 2000\n",
    "\n",
    "  #Kafka container node1\n",
    "  broker1:\n",
    "    image: confluentinc/cp-server\n",
    "    hostname: broker1\n",
    "    container_name: broker1\n",
    "    healthcheck:\n",
    "      test: nc -z localhost 9092\n",
    "    networks:\n",
    "      - hw05-project\n",
    "    depends_on:\n",
    "      - zookeeper\n",
    "    ports:\n",
    "      - \"9092:9092\"\n",
    "    environment:\n",
    "      KAFKA_BROKER_ID: 1\n",
    "      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'\n",
    "      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT\n",
    "      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT\n",
    "      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker1:29092,PLAINTEXT_HOST://localhost:9092\n",
    "      KAFKA_LISTENERS: PLAINTEXT://:29092,PLAINTEXT_HOST://:9092\n",
    "      KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter\n",
    "      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1\n",
    "      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0\n",
    "      KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1\n",
    "      KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: 1\n",
    "      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1\n",
    "      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1\n",
    "      KAFKA_JMX_PORT: 9101\n",
    "      KAFKA_JMX_HOSTNAME: localhost\n",
    "      KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL: http://schema-registry:8081\n",
    "      CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: broker1:29092\n",
    "      CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 1\n",
    "      CONFLUENT_METRICS_ENABLE: 'false'\n",
    "      CONFLUENT_SUPPORT_CUSTOMER_ID: 'anonymous'\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the local cluster.\n",
    "\n",
    "```bash\n",
    "(BDA2023) manny@LAPTOP-85L1BUVJ:~/dev/cscie-63/hw05/docker$ docker-compose up -d\n",
    "[+] Running 15/15\n",
    " ⠿ broker1 Pulled                                                                                                                                                                                                     95.0s\n",
    "   ⠿ 3550ee360766 Pull complete                                                                                                                                                                                       14.5s\n",
    "   ⠿ e3455c6406eb Pull complete                                                                                                                                                                                       69.3s\n",
    "   ⠿ 95cdaa6975d4 Pull complete                                                                                                                                                                                       69.9s\n",
    "   ⠿ 3d3883ed71ab Pull complete                                                                                                                                                                                       70.2s\n",
    "   ⠿ c5df82bd3053 Pull complete                                                                                                                                                                                       70.9s\n",
    "   ⠿ 40036816fad0 Pull complete                                                                                                                                                                                       71.0s\n",
    "   ⠿ f7e8fecc2b94 Pull complete                                                                                                                                                                                       71.1s\n",
    "   ⠿ e80d13bd6d87 Pull complete                                                                                                                                                                                       71.2s\n",
    "   ⠿ a11e73b0229d Pull complete                                                                                                                                                                                       71.3s\n",
    "   ⠿ 56e56e5cfea4 Pull complete                                                                                                                                                                                       93.4s\n",
    "   ⠿ cbda59915832 Pull complete                                                                                                                                                                                       93.5s\n",
    " ⠿ zookeeper Pulled                                                                                                                                                                                                   75.8s\n",
    "   ⠿ d23edc08b858 Pull complete                                                                                                                                                                                       74.2s\n",
    "   ⠿ 9b1cb94f7c7c Pull complete                                                                                                                                                                                       74.3s\n",
    "[+] Running 0/1\n",
    "[+] Running 3/3-net  Creating                                                                                                                                                                                          0.1s\n",
    " ⠿ Network hw05-net     Created                                                                                                                                                                                        0.2s\n",
    " ⠿ Container zookeeper  Started                                                                                                                                                                                        2.7s\n",
    " ⠿ Container broker1    Started \n",
    "\n",
    " # Check cluster status\n",
    "(BDA2023) manny@LAPTOP-85L1BUVJ:~/dev/cscie-63/hw05/docker$ docker ps\n",
    "CONTAINER ID   IMAGE                       COMMAND                  CREATED         STATUS                   PORTS                                        NAMES\n",
    "9a6166ddd9c8   confluentinc/cp-server      \"/etc/confluent/dock…\"   8 minutes ago   Up 8 minutes (healthy)   0.0.0.0:9092->9092/tcp                       broker1\n",
    "f73de8275331   confluentinc/cp-zookeeper   \"/etc/confluent/dock…\"   8 minutes ago   Up 8 minutes             2888/tcp, 0.0.0.0:2181->2181/tcp, 3888/tcp   zookeeper\n",
    "\n",
    "# Stop zookeeper\n",
    "(BDA2023) manny@LAPTOP-85L1BUVJ:~/dev/cscie-63/hw05/docker$ docker stop zookeeper\n",
    "zookeeper\n",
    "(BDA2023) manny@LAPTOP-85L1BUVJ:~/dev/cscie-63/hw05/docker$ docker ps\n",
    "CONTAINER ID   IMAGE                    COMMAND                  CREATED          STATUS                    PORTS                    NAMES\n",
    "9a6166ddd9c8   confluentinc/cp-server   \"/etc/confluent/dock…\"   11 minutes ago   Up 11 minutes (healthy)   0.0.0.0:9092->9092/tcp   broker1\n",
    "\n",
    "# Alternatively\n",
    "(BDA2023) manny@LAPTOP-85L1BUVJ:~/dev/cscie-63/hw05/docker$ docker exec -it zookeeper bash\n",
    "[appuser@zookeeper ~]$ /bin/zookeeper-server-stop\n",
    "[appuser@zookeeper ~]$ (BDA2023) manny@LAPTOP-85L1BUVJ:~/dev/cscie-63/hw05/docker$ docker ps\n",
    "CONTAINER ID   IMAGE                    COMMAND                  CREATED             STATUS                    PORTS                    NAMES\n",
    "9a6166ddd9c8   confluentinc/cp-server   \"/etc/confluent/dock…\"   About an hour ago   Up 59 minutes (healthy)   0.0.0.0:9092->9092/tcp   broker1\n",
    "\n",
    "# Start zookeeper running ports showing for server/broker and zookeeper\n",
    "(BDA2023) manny@LAPTOP-85L1BUVJ:~/dev/cscie-63/hw05/docker$ docker-compose start zookeeper\n",
    "[+] Running 1/1\n",
    " ⠿ Container zookeeper  Started                                                                                                                                                                                        0.4s\n",
    "(BDA2023) manny@LAPTOP-85L1BUVJ:~/dev/cscie-63/hw05/docker$ docker-compose ps\n",
    "NAME                IMAGE                       COMMAND                  SERVICE             CREATED             STATUS                    PORTS\n",
    "broker1             confluentinc/cp-server      \"/etc/confluent/dock…\"   broker1             12 minutes ago      Up 12 minutes (healthy)   0.0.0.0:9092->9092/tcp\n",
    "zookeeper           confluentinc/cp-zookeeper   \"/etc/confluent/dock…\"   zookeeper           12 minutes ago      Up 12 seconds             2888/tcp, 0.0.0.0:2181->2181/tcp, 3888/tcp\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3. \n",
    "Create two new topics. Name topics following your first name and the last names. If you are John Smith, one topic should be named John and the other Smith. List existing topics using console commands. Describe both topics using console commands."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "# Create firstname topic\n",
    "(BDA2023) manny@LAPTOP-85L1BUVJ:~/dev/cscie-63/hw05/docker$ docker exec -it broker1 /bin/kafka-topics --bootstrap-server broker1:29092 --create --topic Manny --partitions 1\n",
    "Created topic Manny.\n",
    "\n",
    "# Create topic lastname\n",
    "(BDA2023) manny@LAPTOP-85L1BUVJ:~/dev/cscie-63/hw05/docker$ docker exec -it broker1 /bin/kafka-topics --bootstrap-server broker1:29092 --create --topic Aboah --partitions 1\n",
    "Created topic Aboah.\n",
    "\n",
    "# List topics\n",
    "(BDA2023) manny@LAPTOP-85L1BUVJ:~/dev/cscie-63/hw05/docker$ docker exec -it broker1  /bin/kafka-topics --bootstrap-server broker1:29092 --list\n",
    "Aboah\n",
    "Manny\n",
    "__consumer_offsets\n",
    "_confluent-command\n",
    "_confluent-metrics\n",
    "_confluent-telemetry-metrics\n",
    "_confluent_balancer_api_state\n",
    "_confluent_balancer_broker_samples\n",
    "_confluent_balancer_partition_samples\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4. \n",
    "Demonstrate that you can publish messages to Kafka and consume messages from Kafka using Kafka console tools. Do that twice. The first time produce and “save” 4 uncompressed messages. Always send messages in the form of key:value pairs.  Find partition or log where those messages were stored and try to read them using one of text editors.  Report on the location of those logs and the content you discovered."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "# Uncompressed messages\n",
    "\n",
    "# Producer\n",
    "> docker exec  -it broker1 /bin/kafka-console-producer --bootstrap-server broker1:29092 --topic Manny\n",
    ">Message 1: Hello \n",
    ">Message 2: World\n",
    ">Message 3: Fun\n",
    ">Message 4: Games  \n",
    "\n",
    "# Consumer\n",
    "> docker exec -it broker1 /bin/kafka-console-consumer --bootstrap-server broker1:29092 --topic Manny\n",
    "Message 1: Hello\n",
    "Message 2: World\n",
    "Message 3: Fun\n",
    "Message 4: Games\n",
    "\n",
    "# Topic logs\n",
    "(BDA2023) manny@LAPTOP-85L1BUVJ:~/dev/cscie-63/hw05/docker$ docker exec  -it broker1 /bin/kafka-run-class kafka.tools.DumpLogSegments --files /var/lib/kafka/data/Manny-0/00000000000000000000.log --print-data-log\n",
    "Dumping /var/lib/kafka/data/Manny-0/00000000000000000000.log\n",
    "Log starting offset: 0\n",
    "baseOffset: 0 lastOffset: 0 count: 1 baseSequence: 0 lastSequence: 0 producerId: 0 producerEpoch: 0 partitionLeaderEpoch: 0 isTransactional: false isControl: false deleteHorizonMs: OptionalLong.empty position: 0 CreateTime: 1677813380594 size: 84 magic: 2 compresscodec: none crc: 3424044466 isvalid: true\n",
    "| offset: 0 CreateTime: 1677813380594 keySize: -1 valueSize: 16 sequence: 0 headerKeys: [] payload: Message 1: Hello\n",
    "baseOffset: 1 lastOffset: 1 count: 1 baseSequence: 1 lastSequence: 1 producerId: 0 producerEpoch: 0 partitionLeaderEpoch: 0 isTransactional: false isControl: false deleteHorizonMs: OptionalLong.empty position: 84 CreateTime: 1677813406214 size: 84 magic: 2 compresscodec: none crc: 2878688754 isvalid: true\n",
    "| offset: 1 CreateTime: 1677813406214 keySize: -1 valueSize: 16 sequence: 1 headerKeys: [] payload: Message 2: World\n",
    "baseOffset: 2 lastOffset: 2 count: 1 baseSequence: 2 lastSequence: 2 producerId: 0 producerEpoch: 0 partitionLeaderEpoch: 0 isTransactional: false isControl: false deleteHorizonMs: OptionalLong.empty position: 168 CreateTime: 1677813420440 size: 82 magic: 2 compresscodec: none crc: 2325924200 isvalid: true\n",
    "| offset: 2 CreateTime: 1677813420440 keySize: -1 valueSize: 14 sequence: 2 headerKeys: [] payload: Message 3: Fun\n",
    "baseOffset: 3 lastOffset: 3 count: 1 baseSequence: 3 lastSequence: 3 producerId: 0 producerEpoch: 0 partitionLeaderEpoch: 0 isTransactional: false isControl: false deleteHorizonMs: OptionalLong.empty position: 250 CreateTime: 1677813438626 size: 84 magic: 2 compresscodec: none crc: 3076656657 isvalid: true\n",
    "| offset: 3 CreateTime: 1677813438626 keySize: -1 valueSize: 16 sequence: 3 headerKeys: [] payload: Message 4: Games \n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 5. \n",
    "Repeat the tasks of Problem 4, this time saving messages in one of compressed forms. Please tell us how you made the broker compress the messages. Again, open the topic partition with a Vi or some other text editor and examine stored messages."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "# Compressed message\n",
    "\n",
    "# Create compressed message topic\n",
    "(BDA2023) manny@LAPTOP-85L1BUVJ:~/dev/cscie-63$ docker exec -it broker1 /bin/kafka-topics --bootstrap-server broker1:29092 --create --topic manny-compressed-topic --config compression.type=gzip --replication-factor 1 --partitions 1\n",
    "Created topic manny-compressed-topic.\n",
    "\n",
    "# Producer - compressed\n",
    "(BDA2023) manny@LAPTOP-85L1BUVJ:~/dev/cscie-63$ docker exec  -it broker1 /bin/kafka-console-producer --bootstrap-server broker1:29092 --topic manny-compressed-topic\n",
    ">m1: This\n",
    ">m2: is a \n",
    ">m3: compressed\n",
    ">m3: message :)\n",
    "\n",
    "# Consumer - compressed\n",
    "(BDA2023) manny@LAPTOP-85L1BUVJ:~/dev/cscie-63$ docker exec -it broker1 /bin/kafka-console-consumer --bootstrap-server broker1:29092 --topic manny-compressed-topic\n",
    "m1: This\n",
    "m2: is a\n",
    "m3: compressed\n",
    "m3: message :)\n",
    "\n",
    "# Topic logs\n",
    "(BDA2023) manny@LAPTOP-85L1BUVJ:~/dev/cscie-63/hw05/docker$ docker exec  -it broker1 /bin/kafka-run-class kafka.tools.DumpLogSegments --files /var/lib/kafka/data/manny-compressed-topic-0/00000000000000000000.log --print-data-log\n",
    "Dumping /var/lib/kafka/data/manny-compressed-topic-0/00000000000000000000.log\n",
    "Log starting offset: 0\n",
    "baseOffset: 0 lastOffset: 0 count: 1 baseSequence: 0 lastSequence: 0 producerId: 1 producerEpoch: 0 partitionLeaderEpoch: 0 isTransactional: false isControl: false deleteHorizonMs: OptionalLong.empty position: 0 CreateTime: 1677814327219 size: 96 magic: 2 compresscodec: gzip crc: 211065228 isvalid: true\n",
    "| offset: 0 CreateTime: 1677814327219 keySize: -1 valueSize: 8 sequence: 0 headerKeys: [] payload: m1: This\n",
    "baseOffset: 1 lastOffset: 1 count: 1 baseSequence: 1 lastSequence: 1 producerId: 1 producerEpoch: 0 partitionLeaderEpoch: 0 isTransactional: false isControl: false deleteHorizonMs: OptionalLong.empty position: 96 CreateTime: 1677814335441 size: 96 magic: 2 compresscodec: gzip crc: 3224285084 isvalid: true\n",
    "| offset: 1 CreateTime: 1677814335441 keySize: -1 valueSize: 8 sequence: 1 headerKeys: [] payload: m2: is a\n",
    "baseOffset: 2 lastOffset: 2 count: 1 baseSequence: 2 lastSequence: 2 producerId: 1 producerEpoch: 0 partitionLeaderEpoch: 0 isTransactional: false isControl: false deleteHorizonMs: OptionalLong.empty position: 192 CreateTime: 1677814343813 size: 102 magic: 2 compresscodec: gzip crc: 1550876762 isvalid: true\n",
    "| offset: 2 CreateTime: 1677814343813 keySize: -1 valueSize: 14 sequence: 2 headerKeys: [] payload: m3: compressed\n",
    "baseOffset: 3 lastOffset: 3 count: 1 baseSequence: 3 lastSequence: 3 producerId: 1 producerEpoch: 0 partitionLeaderEpoch: 0 isTransactional: false isControl: false deleteHorizonMs: OptionalLong.empty position: 294 CreateTime: 1677814352493 size: 102 magic: 2 compresscodec: gzip crc: 4116475984 isvalid: true\n",
    "| offset: 3 CreateTime: 1677814352493 keySize: -1 valueSize: 14 sequence: 3 headerKeys: [] payload: m3: message :)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 6. \n",
    "Please visit Confluent Web site (https://www.confluent.io/ ) and locate the latest versions of Python code for a Kafka producer and Kafka consumer. Please provide us with the URL of the page where you located either code. If there are any differences in the formulation as compared to the code on slides 62 and 64 and 65 of the lecture notes, please report on the differences. Make two clients code taken from Confluent work. As a message to the topic, please use the JSON object described on slide 94 of the lecture notes. Your code should read a text file containing that JSON object. Submit working code and captured dialogues. You need to create the topic before you start the producer and the consumer.\n",
    "\n",
    "References:\n",
    "- [Python Producer](https://developer.confluent.io/get-started/python/#build-producer)\n",
    "- [Python Consumer](https://developer.confluent.io/get-started/python/#build-consumer)\n",
    "- [Config File](https://developer.confluent.io/get-started/python/#configuration)\n",
    "- [Kafka Docker Setup](https://developer.confluent.io/get-started/python/#kafka-setup)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main differences between the current confluent solution i am using here and the one from the slides are:\n",
    "1. The app in the slides has only function definitions and will require a main method or driver class to exectue the functions.\n",
    "2. The current confluent app uses environment config files to set kafka configurations and properties.\n",
    "3. The current confluent app iterates over two dictionaries and produces messages from them as opposed to the bite encoded (kafkatest *20) string in the slides."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuration file. <br>\n",
    "\n",
    "kafka_env.ini\n",
    "\n",
    "```bash\n",
    "[default]\n",
    "bootstrap.servers=localhost:9092\n",
    "\n",
    "[consumer]\n",
    "group.id=python_group_1\n",
    "\n",
    "# 'auto.offset.reset=earliest' to start reading from the beginning of\n",
    "# the topic if no committed offsets exist.\n",
    "auto.offset.reset=latest\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shoppers Json file.\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"event\": \"SHOPPER_VIEWED_PRODUCT\",\n",
    "    \"shopper\": {\n",
    "        \"id\": \"123\",\n",
    "        \"name\": \"Jane\",\n",
    "        \"ipAddress\": \"70.46.123.145\"\n",
    "    },\n",
    "    \"product\": {\n",
    "        \"sku\": \"aapl-001\",\n",
    "        \"name\": \"iPad\"\n",
    "    },\n",
    "    \"timestamp\": \"2018-10-15T12:01:35Z\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python Producer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import json\n",
    "from argparse import ArgumentParser, FileType\n",
    "from configparser import ConfigParser\n",
    "from confluent_kafka import Producer\n",
    "from uuid import uuid4\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Parse the command line.\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument('config_file', type=FileType('r'))\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Parse the configuration.\n",
    "    # See https://github.com/edenhill/librdkafka/blob/master/CONFIGURATION.md\n",
    "    config_parser = ConfigParser()\n",
    "    config_parser.read_file(args.config_file)\n",
    "    config = dict(config_parser['default'])\n",
    "\n",
    "    # Create Producer instance\n",
    "    producer = Producer(config)\n",
    "\n",
    "    # Optional per-message delivery callback (triggered by poll() or flush())\n",
    "    # when a message has been successfully delivered or permanently\n",
    "    # failed delivery (after retries).\n",
    "    def delivery_callback(err, msg):\n",
    "        if err:\n",
    "            print('ERROR: Message failed delivery: {}'.format(err))\n",
    "        else:\n",
    "            print(\"Produced event to topic {topic}: key = {key:12} value = {value:12}\".format(\n",
    "                topic=msg.topic(), key=msg.key().decode('utf-8'), value=msg.value().decode('utf-8')))\n",
    "\n",
    "    # Produce data by selecting random values from these lists.\n",
    "    topic = \"shopper\"\n",
    "    json_data = open(\"shopper_data.json\")\n",
    "    data = str(json.load(json_data)).encode()\n",
    "\n",
    "    try:\n",
    "        producer.produce(topic=topic, key=str(uuid4()), value=data, callback=delivery_callback)\n",
    "        # Block until the messages are sent.\n",
    "        producer.poll(10000)\n",
    "        producer.flush()\n",
    "    except Exception as ex:\n",
    "        print(\"Exception happend: \", ex)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output\n",
    "\n",
    "```bash\n",
    "(BDA2023) manny@LAPTOP-85L1BUVJ:~/dev/cscie-63/hw05/python$ python producer.py kafa_env.ini\n",
    "Produced event to topic shopper: key = 6ae07532-0108-4aaa-ae56-e90b5d4bcddb value = {'event': 'SHOPPER_VIEWED_PRODUCT', 'shopper': {'id': '123', 'name': 'Jane', 'ipAddress': '70.46.123.145'}, 'product': {'sku': 'aapl-001', 'name': 'iPad'}, 'timestamp': '2018-10-15T12:01:35Z'}\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consumer App\n",
    "\n",
    "```python\n",
    "from argparse import ArgumentParser, FileType\n",
    "from configparser import ConfigParser\n",
    "from confluent_kafka import Consumer, OFFSET_BEGINNING\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Parse the command line.\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument('config_file', type=FileType('r'))\n",
    "    parser.add_argument('--reset', action='store_true')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Parse the configuration.\n",
    "    # See https://github.com/edenhill/librdkafka/blob/master/CONFIGURATION.md\n",
    "    config_parser = ConfigParser()\n",
    "    config_parser.read_file(args.config_file)\n",
    "    config = dict(config_parser['default'])\n",
    "    config.update(config_parser['consumer'])\n",
    "\n",
    "    # Create Consumer instance\n",
    "    consumer = Consumer(config)\n",
    "\n",
    "    # Set up a callback to handle the '--reset' flag.\n",
    "    def reset_offset(consumer, partitions):\n",
    "        if args.reset:\n",
    "            for p in partitions:\n",
    "                p.offset = OFFSET_BEGINNING\n",
    "            consumer.assign(partitions)\n",
    "\n",
    "    # Subscribe to topic\n",
    "    topic = \"shopper\"\n",
    "    consumer.subscribe([topic], on_assign=reset_offset)\n",
    "\n",
    "    # Poll for new messages from Kafka and print them.\n",
    "    try:\n",
    "        while True:\n",
    "            msg = consumer.poll(1.0)\n",
    "            if msg is None:\n",
    "                # Initial message consumption may take up to\n",
    "                # `session.timeout.ms` for the consumer group to\n",
    "                # rebalance and start consuming\n",
    "                print(\"Waiting...\")\n",
    "            elif msg.error():\n",
    "                print(\"ERROR: %s\".format(msg.error()))\n",
    "            else:\n",
    "                # Extract the (optional) key and value, and print.\n",
    "\n",
    "                print(\"Consumed event from topic {topic}: key = {key} value = {value}\".format(\n",
    "                    topic=msg.topic(), key=msg.key().decode('utf-8'), value=msg.value().decode('utf-8')))\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    finally:\n",
    "        # Leave group and commit final offsets\n",
    "        consumer.close()\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output\n",
    "\n",
    "```bash\n",
    "(BDA2023) manny@LAPTOP-85L1BUVJ:~/dev/cscie-63/hw05/python$ python consumer.py kafa_env.ini\n",
    "Consumed event from topic shopper: key = 6ae07532-0108-4aaa-ae56-e90b5d4bcddb value = {'event': 'SHOPPER_VIEWED_PRODUCT', 'shopper': {'id': '123', 'name': 'Jane', 'ipAddress': '70.46.123.145'}, 'product': {'sku': 'aapl-001', 'name': 'iPad'}, 'timestamp': '2018-10-15T12:01:35Z'}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BDA2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cee759d8ba3d05fbc0ce9d562811c528771065e3ebcaa60876c1a7482c086180"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
