{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HU Extension                     Assignment 04           E63 Big Data Analytics\n",
    "## Issued on: Feb 17, 2023                        Due on Saturday by 11:59 AM EST, Feb 25, 2023\n",
    "## Emmanuel Aboah"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1. \n",
    "Expand provided archive test_db-master.zip. You will see file employees.sql which you could use to create MySQL database employees. In the directory where that file resides run:\n",
    "mysql --user=root --password < employees.sql\n",
    "Provide the password and the database will be created and loaded.\n",
    "Using MySQL prompt, find the total number of departments and the number of employees in each department. \n",
    "Your second result should include names of the departments.\n",
    "From table dept_emp, delete all rows representing the department with the smallest number of employees.\n",
    "Into table departments insert new department named “Entertainment”. \n",
    "Into table employees insert one new employee named “John Smith”."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create schema and load data\n",
    "\n",
    "```bash\n",
    "mysql --user=root --password < employees.sql\n",
    "\n",
    "# Output:\n",
    "Enter password: \n",
    "INFO\n",
    "CREATING DATABASE STRUCTURE\n",
    "INFO\n",
    "storage engine: InnoDB\n",
    "INFO\n",
    "LOADING departments\n",
    "INFO\n",
    "LOADING employees\n",
    "INFO\n",
    "LOADING dept_emp\n",
    "INFO\n",
    "LOADING dept_manager\n",
    "INFO\n",
    "LOADING titles\n",
    "INFO\n",
    "LOADING salaries\n",
    "data_load_time_diff\n",
    "00:01:23\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the total number of departments and the number of employees in each department.\n",
    "\n",
    "```bash\n",
    "# Total number of departments.\n",
    "mysql> select count(*) from departments;\n",
    "+----------+\n",
    "| count(*) |\n",
    "+----------+\n",
    "|        9 |\n",
    "+----------+\n",
    "1 row in set (0.00 sec)\n",
    "\n",
    "# Number of employees in each department.\n",
    "mysql> select de.dept_no, d.dept_name, count(de.emp_no) as total_emps \n",
    "    -> from dept_emp de\n",
    "    -> join departments d on de.dept_no = d.dept_no\n",
    "    -> group by dept_no;\n",
    "+---------+--------------------+------------+\n",
    "| dept_no | dept_name          | total_emps |\n",
    "+---------+--------------------+------------+\n",
    "| d005    | Development        |      85707 |\n",
    "| d007    | Sales              |      52245 |\n",
    "| d004    | Production         |      73485 |\n",
    "| d003    | Human Resources    |      17786 |\n",
    "| d008    | Research           |      21126 |\n",
    "| d006    | Quality Management |      20117 |\n",
    "| d009    | Customer Service   |      23580 |\n",
    "| d001    | Marketing          |      20211 |\n",
    "| d002    | Finance            |      17346 |\n",
    "+---------+--------------------+------------+\n",
    "\n",
    "# Department with least number of employees.\n",
    "select de.dept_no, d.dept_name, count(de.emp_no) as total_emps \n",
    "    -> from dept_emp de\n",
    "    -> join departments d on de.dept_no = d.dept_no\n",
    "    -> group by dept_no\n",
    "    -> order by total_emps asc limit 1;\n",
    "+---------+-----------+------------+\n",
    "| dept_no | dept_name | total_emps |\n",
    "+---------+-----------+------------+\n",
    "| d002    | Finance   |      17346 |\n",
    "+---------+-----------+------------+\n",
    "1 row in set (0.79 sec)\n",
    "\n",
    "# From table dept_emp, Delete all rows representing the department with the smallest number of employees.\n",
    "mysql> delete from dept_emp where dept_no = 'd002';\n",
    "17346 row(s) affected\t0.719 sec\n",
    "# Proof:\n",
    "mysql> select * from dept_emp where dept_no = 'd002';\n",
    "Empty set (0.23 sec)\n",
    "\n",
    "# Into table departments insert new department named “Entertainment”. \n",
    "mysql> insert into departments (dept_no, dept_name) values('d010', 'Entertainment');\n",
    "Query OK, 1 row affected (0.01 sec)\n",
    "# Proof\n",
    "mysql> select * from departments where dept_no = 'd010';\n",
    "+---------+---------------+\n",
    "| dept_no | dept_name     |\n",
    "+---------+---------------+\n",
    "| d010    | Entertainment |\n",
    "+---------+---------------+\n",
    "1 row in set (0.00 sec)\n",
    "\n",
    "# Into table employees insert one new employee named “John Smith”.\n",
    "INSERT INTO employees (emp_no, birth_date, first_name, last_name, gender, hire_date) VALUES ('500000', '1990-10-10', 'John', 'Smith', 'M', '2019-10-10');\n",
    "Query OK, 1 row affected (0.03 sec)\n",
    "# Proof:\n",
    "mysql> select * from employees where emp_no = 500000;\n",
    "+--------+------------+------------+-----------+--------+------------+\n",
    "| emp_no | birth_date | first_name | last_name | gender | hire_date  |\n",
    "+--------+------------+------------+-----------+--------+------------+\n",
    "| 500000 | 1990-10-10 | John       | Smith     | M      | 2019-10-10 |\n",
    "+--------+------------+------------+-----------+--------+------------+\n",
    "1 row in set (0.00 sec)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2. \n",
    "On the Spark side, create Data Frames df_employees, df_dept_emp and df_departments and populate them with the contents of tables employees, dept_emp and departments from the above database. \n",
    "Using DataFrame API or spark.SQL statements create to new DataFrames: employee (name in singular) and department (name in singular). \n",
    "DataFrame employee will contain all the rows and columns of df_employees plus properly populated dept_no column. \n",
    "DataFrame department will contain all the columns of the DataFrame df_departments. Using those two new DataFrames, create and populate corresponding table in MySQL database employee and department. Report on the number of rows in each MySQL table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "import findspark\n",
    "\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set context and configs\n",
    "conf = SparkConf().setMaster(\"local\").setAppName(\"Hw04App\")\n",
    "\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SparkSession\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using spark, create Data Frames df_employees, df_dept_emp and df_departments and populate them with the contents of tables employees, dept_emp and departments from the above database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- emp_no: integer (nullable = true)\n",
      " |-- birth_date: date (nullable = true)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- hire_date: date (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 505:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+----------+---------+------+----------+\n",
      "|emp_no|birth_date|first_name|last_name|gender| hire_date|\n",
      "+------+----------+----------+---------+------+----------+\n",
      "| 10001|1953-09-02|    Georgi|  Facello|     M|1986-06-26|\n",
      "| 10002|1964-06-02|   Bezalel|   Simmel|     F|1985-11-21|\n",
      "| 10003|1959-12-03|     Parto|  Bamford|     M|1986-08-28|\n",
      "| 10004|1954-05-01| Chirstian|  Koblick|     M|1986-12-01|\n",
      "| 10005|1955-01-21|   Kyoichi| Maliniak|     M|1989-09-12|\n",
      "+------+----------+----------+---------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# employees\n",
    "df_employees = (\n",
    "    spark.read\n",
    "    .format(\"jdbc\")\n",
    "    .option(\"url\",\"jdbc:mysql://127.0.0.1:3306\")\n",
    "    .option(\"driver\",\"com.mysql.cj.jdbc.Driver\")\n",
    "    .option(\"dbtable\", \"employees.employees\")\n",
    "    .option(\"user\", \"root\")\n",
    "    .option(\"password\", \"password\")\n",
    "    .load()\n",
    ")\n",
    "\n",
    "df_employees.printSchema()\n",
    "\n",
    "df_employees.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- emp_no: integer (nullable = true)\n",
      " |-- dept_no: string (nullable = true)\n",
      " |-- from_date: date (nullable = true)\n",
      " |-- to_date: date (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 368:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+----------+----------+\n",
      "|emp_no|dept_no| from_date|   to_date|\n",
      "+------+-------+----------+----------+\n",
      "| 10001|   d005|1986-06-26|9999-01-01|\n",
      "| 10002|   d007|1996-08-03|9999-01-01|\n",
      "| 10003|   d004|1995-12-03|9999-01-01|\n",
      "| 10004|   d004|1986-12-01|9999-01-01|\n",
      "| 10005|   d003|1989-09-12|9999-01-01|\n",
      "+------+-------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# dept_emp\n",
    "df_dept_emp = (\n",
    "    spark.read\n",
    "    .format(\"jdbc\")\n",
    "    .option(\"url\",\"jdbc:mysql://127.0.0.1:3306\")\n",
    "    .option(\"driver\",\"com.mysql.cj.jdbc.Driver\")\n",
    "    .option(\"dbtable\", \"employees.dept_emp\")\n",
    "    .option(\"user\", \"root\")\n",
    "    .option(\"password\", \"password\")\n",
    "    .load()\n",
    ")\n",
    "\n",
    "df_dept_emp.printSchema()\n",
    "\n",
    "df_dept_emp.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dept_no: string (nullable = true)\n",
      " |-- dept_name: string (nullable = true)\n",
      "\n",
      "+-------+------------------+\n",
      "|dept_no|         dept_name|\n",
      "+-------+------------------+\n",
      "|   d009|  Customer Service|\n",
      "|   d005|       Development|\n",
      "|   d010|     Entertainment|\n",
      "|   d002|           Finance|\n",
      "|   d003|   Human Resources|\n",
      "|   d001|         Marketing|\n",
      "|   d004|        Production|\n",
      "|   d006|Quality Management|\n",
      "|   d008|          Research|\n",
      "|   d007|             Sales|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# departments\n",
    "df_departments = (\n",
    "    spark.read\n",
    "    .format(\"jdbc\")\n",
    "    .option(\"url\",\"jdbc:mysql://127.0.0.1:3306\")\n",
    "    .option(\"driver\",\"com.mysql.cj.jdbc.Driver\")\n",
    "    .option(\"dbtable\", \"employees.departments\")\n",
    "    .option(\"user\", \"root\")\n",
    "    .option(\"password\", \"password\")\n",
    "    .load()\n",
    ")\n",
    "\n",
    "df_departments.printSchema()\n",
    "\n",
    "df_departments.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using DataFrame API or spark.SQL statements create two new DataFrames: employee (name in singular) and department (name in singular). \n",
    "DataFrame employee will contain all the rows and columns of df_employees plus properly populated dept_no column. DataFrame department will contain all the columns of the DataFrame df_departments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 378:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+----------+---------+------+----------+-------+\n",
      "|emp_no|birth_date|first_name|last_name|gender| hire_date|dept_no|\n",
      "+------+----------+----------+---------+------+----------+-------+\n",
      "| 12046|1961-05-16|     Xiong|    Ranum|     F|1996-01-13|   d001|\n",
      "| 13289|1962-08-12|     Berni|     Baer|     F|1987-09-24|   d001|\n",
      "| 14570|1963-07-26|    Chinho|     Bala|     F|1994-11-17|   d001|\n",
      "| 18024|1952-08-04|       Uzi|Casperson|     M|1987-12-14|   d001|\n",
      "| 23336|1958-10-07|     Kauko|     Suri|     F|1990-04-15|   d001|\n",
      "+------+----------+----------+---------+------+----------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Employee DF\n",
    "df_employee = (\n",
    "    df_employees\n",
    "    .join(df_dept_emp, [\"emp_no\"])\n",
    "    .join(df_departments, [\"dept_no\"])\n",
    "    .select(df_employees[\"*\"], df_dept_emp[\"dept_no\"])\n",
    "    )\n",
    "\n",
    "df_employee.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|dept_no|         dept_name|\n",
      "+-------+------------------+\n",
      "|   d009|  Customer Service|\n",
      "|   d005|       Development|\n",
      "|   d010|     Entertainment|\n",
      "|   d002|           Finance|\n",
      "|   d003|   Human Resources|\n",
      "|   d001|         Marketing|\n",
      "|   d004|        Production|\n",
      "|   d006|Quality Management|\n",
      "|   d008|          Research|\n",
      "|   d007|             Sales|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Department DF\n",
    "df_department = df_departments.select(\"*\")\n",
    "\n",
    "df_department.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using those two new DataFrames, create and populate corresponding table in MySQL database employee and department. Report on the number of rows in each MySQL table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Save employee DF to mysql\n",
    "(\n",
    "    df_employee.repartition(10).write\n",
    "    .format(\"jdbc\")\n",
    "    .option(\"url\",\"jdbc:mysql://127.0.0.1:3306\")\n",
    "    .option(\"driver\",\"com.mysql.cj.jdbc.Driver\")\n",
    "    .option(\"dbtable\", \"employees.employee\")\n",
    "    .option(\"user\", \"root\")\n",
    "    .option(\"password\", \"password\")\n",
    "    .mode(\"overwrite\")\n",
    "    .save()\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "# employee table count in mysql:\n",
    "mysql> select count(*) from employee;\n",
    "+----------+\n",
    "| count(*) |\n",
    "+----------+\n",
    "|   314257 |\n",
    "+----------+\n",
    "1 row in set (0.04 sec)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save department DF to mysql:\n",
    "(\n",
    "    df_department.repartition(5).write\n",
    "    .format(\"jdbc\")\n",
    "    .option(\"url\",\"jdbc:mysql://127.0.0.1:3306\")\n",
    "    .option(\"driver\",\"com.mysql.cj.jdbc.Driver\")\n",
    "    .option(\"dbtable\", \"employees.department\")\n",
    "    .option(\"user\", \"root\")\n",
    "    .option(\"password\", \"password\")\n",
    "    .mode(\"overwrite\")\n",
    "    .save()\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "# Show in MySql\n",
    "mysql> select count(*) from department;\n",
    "+----------+\n",
    "| count(*) |\n",
    "+----------+\n",
    "|       10 |\n",
    "+----------+\n",
    "1 row in set (0.00 sec)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3. \n",
    "On both MySQL side and on the Spark side find the number of employees in each department. Your results should include the name of each department. Please, select rows that have matching values in both tables. Use DataFrames employee and department and MySQL tables employee and department. On the Spark side, perform your query both by using DataFrame API and spark.SQL statements. Is your result different from the initial result obtained in Problem 1?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "# Number of employees in each department [department, employee] tables - MySql\n",
    "mysql> select count(e.emp_no) as total_emp, e.dept_no, d.dept_name from employee e\n",
    "    -> join department d on d.dept_no = e.dept_no\n",
    "    -> group by e.dept_no, d.dept_name;\n",
    "+-----------+---------+--------------------+\n",
    "| total_emp | dept_no | dept_name          |\n",
    "+-----------+---------+--------------------+\n",
    "|     85707 | d005    | Development        |\n",
    "|     73485 | d004    | Production         |\n",
    "|     52245 | d007    | Sales              |\n",
    "|     20117 | d006    | Quality Management |\n",
    "|     23580 | d009    | Customer Service   |\n",
    "|     20211 | d001    | Marketing          |\n",
    "|     17786 | d003    | Human Resources    |\n",
    "|     21126 | d008    | Research           |\n",
    "+-----------+---------+--------------------+\n",
    "8 rows in set (1.20 sec)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of employees in each department - spark sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp view for employee\n",
    "df_employee.createOrReplaceTempView(\"employee\")\n",
    "\n",
    "# temp view for department\n",
    "df_department.createOrReplaceTempView(\"department\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------+------------------+\n",
      "|total_emp_in_dept|dept_no|         dept_name|\n",
      "+-----------------+-------+------------------+\n",
      "|            20211|   d001|         Marketing|\n",
      "|            17786|   d003|   Human Resources|\n",
      "|            73485|   d004|        Production|\n",
      "|            85707|   d005|       Development|\n",
      "|            20117|   d006|Quality Management|\n",
      "|            52245|   d007|             Sales|\n",
      "|            21126|   d008|          Research|\n",
      "|            23580|   d009|  Customer Service|\n",
      "+-----------------+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Number of employees in each department\n",
    "spark.sql(\n",
    "    \"select count(employee.emp_no) as total_emp_in_dept, employee.dept_no, department.dept_name\"\n",
    "    + \" from employee join department on department.dept_no = employee.dept_no\"\n",
    "    + \" group by employee.dept_no, department.dept_name\"\n",
    ").show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of employees in each department -> DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+\n",
      "|dept_no|         dept_name|total_emp_in_dept|\n",
      "+-------+------------------+-----------------+\n",
      "|   d001|         Marketing|            20211|\n",
      "|   d003|   Human Resources|            17786|\n",
      "|   d004|        Production|            73485|\n",
      "|   d005|       Development|            85707|\n",
      "|   d006|Quality Management|            20117|\n",
      "|   d007|             Sales|            52245|\n",
      "|   d008|          Research|            21126|\n",
      "|   d009|  Customer Service|            23580|\n",
      "+-------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joinExp = df_employee[\"dept_no\"] == df_department[\"dept_no\"]\n",
    "\n",
    "agg_count = (\n",
    "    df_employee.alias(\"e\")\n",
    "    .join(df_department.alias(\"d\"), joinExp)\n",
    "    .select(\"e.emp_no\", \"e.dept_no\", \"d.dept_name\")\n",
    "    .groupBy(\"e.dept_no\", \"d.dept_name\")\n",
    "    .agg(count(\"e.emp_no\").alias(\"total_emp_in_dept\"))\n",
    ")\n",
    "\n",
    "agg_count.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is your result different from the initial result obtained in Problem 1?\n",
    "Ans: Yes -> \n",
    "     The results are different because we deleted the row for department d002 (Finance) <br>\n",
    "     ***Note That the new data insterted is not included here becuase the default join is inner-join.***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4. \n",
    "On both MySQL side and on the Spark side find the number of employees in each department. Your results should include the number of employees and the names of department where those employees work. Please include the names of departments which have no matching employees. On the Spark side perform your query both by using DataFrame API and spark.SQL statements."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "# Count of employees in each department, empty departments inclusive - MySql\n",
    "select count(e.emp_no) as total_emp, e.dept_no, d.dept_name from employee e\n",
    "    -> right outer join department d on d.dept_no = e.dept_no\n",
    "    -> group by e.dept_no, d.dept_name;\n",
    "+-----------+---------+--------------------+\n",
    "| total_emp | dept_no | dept_name          |\n",
    "+-----------+---------+--------------------+\n",
    "|     52245 | d007    | Sales              |\n",
    "|     20211 | d001    | Marketing          |\n",
    "|     17786 | d003    | Human Resources    |\n",
    "|     73485 | d004    | Production         |\n",
    "|     23580 | d009    | Customer Service   |\n",
    "|     85707 | d005    | Development        |\n",
    "|     20117 | d006    | Quality Management |\n",
    "|     21126 | d008    | Research           |\n",
    "|         0 | NULL    | Entertainment      |\n",
    "|         0 | NULL    | Finance            |\n",
    "+-----------+---------+--------------------+\n",
    "10 rows in set (1.87 sec)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 479:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------+------------------+\n",
      "|total_emp_in_dept|dept_no|         dept_name|\n",
      "+-----------------+-------+------------------+\n",
      "|                0|   null|     Entertainment|\n",
      "|                0|   null|           Finance|\n",
      "|            52245|   d007|             Sales|\n",
      "|            73485|   d004|        Production|\n",
      "|            17786|   d003|   Human Resources|\n",
      "|            20211|   d001|         Marketing|\n",
      "|            23580|   d009|  Customer Service|\n",
      "|            21126|   d008|          Research|\n",
      "|            85707|   d005|       Development|\n",
      "|            20117|   d006|Quality Management|\n",
      "+-----------------+-------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Count of employees in each department, empty departments inclusive - spark.sql\n",
    "spark.sql(\n",
    "    \"select count(employee.emp_no) as total_emp_in_dept, employee.dept_no, department.dept_name\"\n",
    "    + \" from employee right outer join department on department.dept_no = employee.dept_no\"\n",
    "    + \" group by employee.dept_no, department.dept_name\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+\n",
      "|dept_no|         dept_name|total_emp_in_dept|\n",
      "+-------+------------------+-----------------+\n",
      "|   null|     Entertainment|                0|\n",
      "|   null|           Finance|                0|\n",
      "|   d007|             Sales|            52245|\n",
      "|   d004|        Production|            73485|\n",
      "|   d003|   Human Resources|            17786|\n",
      "|   d001|         Marketing|            20211|\n",
      "|   d009|  Customer Service|            23580|\n",
      "|   d008|          Research|            21126|\n",
      "|   d005|       Development|            85707|\n",
      "|   d006|Quality Management|            20117|\n",
      "+-------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count of employees in each department, empty departments inclusive - DataFrame\n",
    "agg_count_empty = (\n",
    "    df_employee.alias(\"e\")\n",
    "    .join(df_department.alias(\"d\"), joinExp, \"right_outer\")\n",
    "    .select(\"e.emp_no\", \"e.dept_no\", \"d.dept_name\")\n",
    "    .groupBy(\"e.dept_no\", \"d.dept_name\")\n",
    "    .agg(count(\"e.emp_no\").alias(\"total_emp_in_dept\"))\n",
    ")\n",
    "\n",
    "agg_count_empty.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 5. \n",
    "First on the Spark side and then on MySQL side, find the number of employees in each department. Your results should include the names of department(s) which have no matching employees and the number of employees without matching department, if any. On the Spark side perform your query both by using DataFrame API and spark.SQL statements. Your results should include the names of department(s) which have no matching employees and the number of employees without matching department, if any. This problem might require some independent reading due to implementation limitations on MySQL side. If having issues, just report your findings."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First on the Spark side and then on MySQL side, find the number of employees in each department. Your results should include the names of department(s) which have no matching employees and the number of employees without matching department, if any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+\n",
      "|dept_no|         dept_name|total_emp_in_dept|\n",
      "+-------+------------------+-----------------+\n",
      "|   d005|       Development|            85707|\n",
      "|   d009|  Customer Service|            23580|\n",
      "|   d003|   Human Resources|            17786|\n",
      "|   d001|         Marketing|            20211|\n",
      "|   d007|             Sales|            52245|\n",
      "|   d004|        Production|            73485|\n",
      "|   d010|     Entertainment|                0|\n",
      "|   d002|           Finance|                0|\n",
      "|   d006|Quality Management|            20117|\n",
      "|   d008|          Research|            21126|\n",
      "+-------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Number of employees in each department(s), empty departments inclusive - Spark DF\n",
    "\n",
    "# Join Expressions\n",
    "joinExpEmp = df_employees[\"emp_no\"] == df_dept_emp[\"emp_no\"]\n",
    "joinExpDeptEmp = df_departments[\"dept_no\"] == df_dept_emp[\"dept_no\"]\n",
    "\n",
    "# Using department(s) and employee(s) tables \n",
    "(\n",
    "    df_employees.alias(\"e\")\n",
    "    .join(df_dept_emp.alias(\"d\"), joinExpEmp, \"right_outer\")\n",
    "    .join(df_departments.alias(\"de\"), joinExpDeptEmp, \"right_outer\")\n",
    "    .select(\"e.emp_no\", \"de.dept_no\", \"de.dept_name\")\n",
    "    .groupBy(\"de.dept_no\", \"de.dept_name\")\n",
    "    .agg(count(\"e.emp_no\").alias(\"total_emp_in_dept\"))\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp view for employee\n",
    "df_employees.createOrReplaceTempView(\"employees\")\n",
    "\n",
    "# temp view for department\n",
    "df_departments.createOrReplaceTempView(\"departments\")\n",
    "\n",
    "# temp view for dept_emp\n",
    "df_dept_emp.createOrReplaceTempView(\"dept_emp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------+------------------+\n",
      "|total_emp_in_dept|dept_no|         dept_name|\n",
      "+-----------------+-------+------------------+\n",
      "|                0|   null|     Entertainment|\n",
      "|                0|   null|           Finance|\n",
      "|            52245|   d007|             Sales|\n",
      "|            73485|   d004|        Production|\n",
      "|            17786|   d003|   Human Resources|\n",
      "|            20211|   d001|         Marketing|\n",
      "|            23580|   d009|  Customer Service|\n",
      "|            21126|   d008|          Research|\n",
      "|            85707|   d005|       Development|\n",
      "|            20117|   d006|Quality Management|\n",
      "+-----------------+-------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"select count(employees.emp_no) as total_emp_in_dept, dept_emp.dept_no, departments.dept_name\"\n",
    "    + \" from employees\" \n",
    "    + \" right outer join dept_emp on dept_emp.emp_no = employees.emp_no\"\n",
    "    + \" right outer join departments on dept_emp.dept_no = departments.dept_no\"\n",
    "    + \" group by dept_emp.dept_no, departments.dept_name\"\n",
    ").show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of employees that don't have a department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14718"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe\n",
    "(\n",
    "    df_employees.alias(\"e\")\n",
    "    .join(df_dept_emp.alias(\"d\"), joinExpEmp, \"left_anti\")\n",
    "    .count()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|   14718|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# spark.sql\n",
    "\n",
    "spark.sql(\"select count(*) from employees \"\n",
    "    + \"left anti join dept_emp on employees.emp_no = dept_emp.emp_no\").show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Employees with no department - MySql\n",
    "\n",
    "```bash\n",
    "select count(*) from employees e\n",
    "    -> where not exists (select * from dept_emp d where e.emp_no = d.emp_no);\n",
    "+----------+\n",
    "| count(*) |\n",
    "+----------+\n",
    "|    14718 |\n",
    "+----------+\n",
    "1 row in set (1.82 sec)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BDA2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cee759d8ba3d05fbc0ce9d562811c528771065e3ebcaa60876c1a7482c086180"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
