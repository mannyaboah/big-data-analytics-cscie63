{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HU Extension                     Assignment 02           E63 Big Data Analytics\n",
    "## Emmanuel Aboah\n",
    "### Issued on: Feb 03, 2023                            Due by 12 noon EST, Saturday, Feb 11, 2023"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.\n",
    "Consider attached file titanic.txt. It contains: an ordinal number, price of the ticket paid, name of the person, old fashioned gender classification, and the age of a Titanic passenger. Read directly from that file and create and RDD. Display the schema of that RDD. Display the content of that RDD. Similarly, read directly from file books.json and create a DataFrame. Display the schema of that DataFrame. Display the content of that DataFrame. Transform the RDD object into a DataFrame. Convince us that new object is of the expected type. Display the content of new DataFrame. Transform the original DataFrame into an RDD. Convince yourself and us that the transformed object is an RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import Row, SparkSession, SQLContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/10 19:00:31 WARN Utils: Your hostname, LAPTOP-85L1BUVJ resolves to a loopback address: 127.0.1.1; using 172.22.11.167 instead (on interface eth0)\n",
      "23/02/10 19:00:31 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/10 19:00:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# set spark conf and context\n",
    "\n",
    "conf = SparkConf().setMaster(\"local\").setAppName(\"Hw01App\")\n",
    "\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SparkSession\n",
    "\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read textfile\n",
    "\n",
    "titanicRdd = sc.textFile(\"titanic.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(ord_number='1', price='125.00', name='Mr. Owen Harris', gender='male', age='22'),\n",
       " Row(ord_number='2', price='75.00', name='Mrs. Florence Briggs Thayer', gender='female', age='38'),\n",
       " Row(ord_number='3', price='75.00', name='Madame. Laina Heikkinen', gender='female', age='66'),\n",
       " Row(ord_number='4', price='75.00', name='Jacques Heath (Lily May Peel)', gender='female', age='35'),\n",
       " Row(ord_number='5', price='125.00', name='William Henry', gender='male', age='35'),\n",
       " Row(ord_number='6', price='125.00', name='James Moran', gender='male', age='0'),\n",
       " Row(ord_number='7', price='175.00', name='Timothy J McCarthy', gender='male', age='55'),\n",
       " Row(ord_number='8', price='25.00', name='Master Gosta Leonard Palsson', gender='male', age='2'),\n",
       " Row(ord_number='9', price='75.00', name='Mrs. Oscar Johnson (Elisabeth Vilhelmina Berg)', gender='female', age='27'),\n",
       " Row(ord_number='10', price='50.00', name='Miss. Adele Achem', gender='female', age='14')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform RDD to impose schema\n",
    "\n",
    "titanicFields = titanicRdd.map(lambda t: t.split(\",\"))\n",
    "\n",
    "passengers = titanicFields.map(\n",
    "    lambda p: Row(\n",
    "        ord_number = p[0], \n",
    "        price = p[1], \n",
    "        name = p[2], \n",
    "        gender = p[3],\n",
    "        age = p[4]\n",
    "    )\n",
    ")\n",
    "\n",
    "passengers.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ord_number: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+--------------------+------+---+\n",
      "|ord_number| price|                name|gender|age|\n",
      "+----------+------+--------------------+------+---+\n",
      "|         1|125.00|     Mr. Owen Harris|  male| 22|\n",
      "|         2| 75.00|Mrs. Florence Bri...|female| 38|\n",
      "|         3| 75.00|Madame. Laina Hei...|female| 66|\n",
      "|         4| 75.00|Jacques Heath (Li...|female| 35|\n",
      "|         5|125.00|       William Henry|  male| 35|\n",
      "|         6|125.00|         James Moran|  male|  0|\n",
      "|         7|175.00|  Timothy J McCarthy|  male| 55|\n",
      "|         8| 25.00|Master Gosta Leon...|  male|  2|\n",
      "|         9| 75.00|Mrs. Oscar Johnso...|female| 27|\n",
      "|        10| 50.00|   Miss. Adele Achem|female| 14|\n",
      "+----------+------+--------------------+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert rdd to DF and print schema and show data\n",
    "\n",
    "passengersDF = passengers.toDF()\n",
    "\n",
    "passengersDF.printSchema()\n",
    "\n",
    "passengersDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from JSON\n",
    "\n",
    "book_schema = StructType ([\n",
    "    StructField(\"title\", StringType(), True),\n",
    "    StructField(\"author\", StringType(), True),\n",
    "    StructField(\"published\", DateType(), True),\n",
    "    StructField(\"publisher\", StringType(), True),\n",
    "    StructField(\"website\", StringType(), True)\n",
    "])\n",
    "\n",
    "book_json_df = spark.read.option(\"multiline\", \"true\").schema(book_schema).json(\"books.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- author: string (nullable = true)\n",
      " |-- published: date (nullable = true)\n",
      " |-- publisher: string (nullable = true)\n",
      " |-- website: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display passengersJsonDF schema\n",
    "\n",
    "book_json_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+----------+---------------+--------------------+\n",
      "|               title|          author| published|      publisher|             website|\n",
      "+--------------------+----------------+----------+---------------+--------------------+\n",
      "|Eloquent JavaScri...|Marijn Haverbeke|2014-12-14|No Starch Press|http://eloquentja...|\n",
      "|Learning JavaScri...|     Addy Osmani|2012-07-01| O'Reilly Media|http://www.addyos...|\n",
      "+--------------------+----------------+----------+---------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show Data\n",
    "\n",
    "book_json_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show type\n",
    "\n",
    "type(book_json_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to RDD and show type\n",
    "\n",
    "book_json_df_rdd = book_json_df.rdd\n",
    "\n",
    "type(book_json_df_rdd)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2.\n",
    "\n",
    "Read the inferred schema of the DataFrame created when reading file titanic.txt. Modify that schema so that the age of the person is not an Integer or a Long but rather a Float. Try loading titanic.txt with an enforced schema. Report. Make sure that you can load the data with an enforced schema. Display the data content of your DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ord_number: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    " # Show inferred schema\n",
    "\n",
    "passengersDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ord_number: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- age: float (nullable = true)\n",
      "\n",
      "+----------+------+--------------------+------+----+\n",
      "|ord_number| price|                name|gender| age|\n",
      "+----------+------+--------------------+------+----+\n",
      "|         1|125.00|     Mr. Owen Harris|  male|22.0|\n",
      "|         2| 75.00|Mrs. Florence Bri...|female|38.0|\n",
      "|         3| 75.00|Madame. Laina Hei...|female|66.0|\n",
      "|         4| 75.00|Jacques Heath (Li...|female|35.0|\n",
      "|         5|125.00|       William Henry|  male|35.0|\n",
      "|         6|125.00|         James Moran|  male| 0.0|\n",
      "|         7|175.00|  Timothy J McCarthy|  male|55.0|\n",
      "|         8| 25.00|Master Gosta Leon...|  male| 2.0|\n",
      "|         9| 75.00|Mrs. Oscar Johnso...|female|27.0|\n",
      "|        10| 50.00|   Miss. Adele Achem|female|14.0|\n",
      "+----------+------+--------------------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert afe column to float\n",
    "\n",
    "converted_col_df = passengersDF.withColumn(\"age\", passengersDF[\"age\"].cast(FloatType()))\n",
    "\n",
    "converted_col_df.printSchema()\n",
    "\n",
    "converted_col_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ord_number: integer (nullable = true)\n",
      " |-- price: float (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- age: float (nullable = true)\n",
      "\n",
      "+----------+-----+--------------------+------+----+\n",
      "|ord_number|price|                name|gender| age|\n",
      "+----------+-----+--------------------+------+----+\n",
      "|         1|125.0|     Mr. Owen Harris|  male|22.0|\n",
      "|         2| 75.0|Mrs. Florence Bri...|female|38.0|\n",
      "|         3| 75.0|Madame. Laina Hei...|female|66.0|\n",
      "|         4| 75.0|Jacques Heath (Li...|female|35.0|\n",
      "|         5|125.0|       William Henry|  male|35.0|\n",
      "|         6|125.0|         James Moran|  male| 0.0|\n",
      "|         7|175.0|  Timothy J McCarthy|  male|55.0|\n",
      "|         8| 25.0|Master Gosta Leon...|  male| 2.0|\n",
      "|         9| 75.0|Mrs. Oscar Johnso...|female|27.0|\n",
      "|        10| 50.0|   Miss. Adele Achem|female|14.0|\n",
      "+----------+-----+--------------------+------+----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Read titanic with enforced schema\n",
    "\n",
    "passenger_schema = StructType ([\n",
    "    StructField(\"ord_number\", IntegerType(), True),\n",
    "    StructField(\"price\", FloatType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"gender\", StringType(), True),\n",
    "    StructField(\"age\", FloatType(), True)\n",
    "])\n",
    "\n",
    "inf_schema_df = (\n",
    "    spark.read\n",
    "    .option(\"header\", False)\n",
    "    .option(\"infer_schema\", True)\n",
    "    .schema(passenger_schema)\n",
    "    .csv(\"titanic.txt\")\n",
    ")\n",
    "\n",
    "inf_schema_df.printSchema()\n",
    "\n",
    "inf_schema_df.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3.\n",
    "\n",
    "Use the DataFrame created by loading data contained in titanic.txt file. Provide reasonable short names for all columns of that DataFrame. Use DataFrame API and SQL API  to create new DataFrames in which every passenger’s ticket costs 20% less than the originally paid prices, and the ordinal number is multiplied by 10 and provided as a new column with name new_number. Again using both DataFrame API and SQL API select gender, name and age of passengers older than 35 years. Display the content of that DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+------+---+----------+\n",
      "|ord_number|less_price|                name|gender|age|new_number|\n",
      "+----------+----------+--------------------+------+---+----------+\n",
      "|         1|     100.0|     Mr. Owen Harris|  male| 22|      10.0|\n",
      "|         2|      60.0|Mrs. Florence Bri...|female| 38|      20.0|\n",
      "|         3|      60.0|Madame. Laina Hei...|female| 66|      30.0|\n",
      "|         4|      60.0|Jacques Heath (Li...|female| 35|      40.0|\n",
      "|         5|     100.0|       William Henry|  male| 35|      50.0|\n",
      "|         6|     100.0|         James Moran|  male|  0|      60.0|\n",
      "|         7|     140.0|  Timothy J McCarthy|  male| 55|      70.0|\n",
      "|         8|      20.0|Master Gosta Leon...|  male|  2|      80.0|\n",
      "|         9|      60.0|Mrs. Oscar Johnso...|female| 27|      90.0|\n",
      "|        10|      40.0|   Miss. Adele Achem|female| 14|     100.0|\n",
      "+----------+----------+--------------------+------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# converted titanic passengers data Dataframe API\n",
    "\n",
    "conv_passengers_df = passengersDF.select(\n",
    "    passengersDF[0], \n",
    "    expr(\"price - (price * .20) as less_price\"),\n",
    "    passengersDF[2], \n",
    "    passengersDF[3], \n",
    "    passengersDF[4],\n",
    "    expr(\"ord_number * 10 as new_number\")\n",
    ")\n",
    "\n",
    "conv_passengers_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  converted titanic passengers data SQL API\n",
    "\n",
    "passengersDF.createGlobalTempView(\"passengers\")\n",
    "\n",
    "sql_pass_df = spark.sql(\"select ord_number, price - (price * .20) as less_price, name, gender, age, ord_number * 10 as new_number from global_temp.passengers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+------+---+----------+\n",
      "|ord_number|less_price|                name|gender|age|new_number|\n",
      "+----------+----------+--------------------+------+---+----------+\n",
      "|         1|     100.0|     Mr. Owen Harris|  male| 22|      10.0|\n",
      "|         2|      60.0|Mrs. Florence Bri...|female| 38|      20.0|\n",
      "|         3|      60.0|Madame. Laina Hei...|female| 66|      30.0|\n",
      "|         4|      60.0|Jacques Heath (Li...|female| 35|      40.0|\n",
      "|         5|     100.0|       William Henry|  male| 35|      50.0|\n",
      "|         6|     100.0|         James Moran|  male|  0|      60.0|\n",
      "|         7|     140.0|  Timothy J McCarthy|  male| 55|      70.0|\n",
      "|         8|      20.0|Master Gosta Leon...|  male|  2|      80.0|\n",
      "|         9|      60.0|Mrs. Oscar Johnso...|female| 27|      90.0|\n",
      "|        10|      40.0|   Miss. Adele Achem|female| 14|     100.0|\n",
      "+----------+----------+--------------------+------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show data\n",
    "\n",
    "sql_pass_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+\n",
      "|                name|age|\n",
      "+--------------------+---+\n",
      "|     Mr. Owen Harris| 22|\n",
      "|         James Moran|  0|\n",
      "|Master Gosta Leon...|  2|\n",
      "|Mrs. Oscar Johnso...| 27|\n",
      "|   Miss. Adele Achem| 14|\n",
      "+--------------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Passengers older than 35\n",
    "\n",
    "passengersDF.filter(passengersDF['age'] < 35).select(passengersDF['name'], passengersDF['age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passengers > 35 years of age SQL API\n",
    "\n",
    "sql_age_df = spark.sql(\"select name, age from global_temp.passengers where age < 35\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+\n",
      "|                name| age|\n",
      "+--------------------+----+\n",
      "|     Mr. Owen Harris|22.0|\n",
      "|         James Moran| 0.0|\n",
      "|Master Gosta Leon...| 2.0|\n",
      "|Mrs. Oscar Johnso...|27.0|\n",
      "|   Miss. Adele Achem|14.0|\n",
      "+--------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#show data\n",
    "\n",
    "sql_age_df.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4.\n",
    "\n",
    "Read file books.json as a DataFrame and than persist that DataFrame as a CSV file and a Parquet file. Subsequently, read the data from those files into new DataFrames. Demonstrate that the data content is not changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- author: string (nullable = true)\n",
      " |-- published: date (nullable = true)\n",
      " |-- publisher: string (nullable = true)\n",
      " |-- website: string (nullable = true)\n",
      "\n",
      "+--------------------+----------------+----------+---------------+--------------------+\n",
      "|               title|          author| published|      publisher|             website|\n",
      "+--------------------+----------------+----------+---------------+--------------------+\n",
      "|Eloquent JavaScri...|Marijn Haverbeke|2014-12-14|No Starch Press|http://eloquentja...|\n",
      "|Learning JavaScri...|     Addy Osmani|2012-07-01| O'Reilly Media|http://www.addyos...|\n",
      "+--------------------+----------------+----------+---------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read Books json with schema into a dataframe\n",
    "\n",
    "books_df = spark.read.option(\"multiline\", \"true\").schema(book_schema).json(\"books.json\")\n",
    "\n",
    "books_df.printSchema()\n",
    "\n",
    "books_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to csv file\n",
    "\n",
    "books_df.write.option(\"header\",True).option(\"infer_schema\", True).csv(\"/home/manny/dev/cscie-63/hw02/output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to parquet\n",
    "\n",
    "books_df.write.option(\"header\",True).option(\"infer_schema\", True).parquet(\"/home/manny/dev/cscie-63/hw02/outputII\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- author: string (nullable = true)\n",
      " |-- published: string (nullable = true)\n",
      " |-- publisher: string (nullable = true)\n",
      " |-- website: string (nullable = true)\n",
      "\n",
      "+--------------------+----------------+----------+---------------+--------------------+\n",
      "|               title|          author| published|      publisher|             website|\n",
      "+--------------------+----------------+----------+---------------+--------------------+\n",
      "|Eloquent JavaScri...|Marijn Haverbeke|2014-12-14|No Starch Press|http://eloquentja...|\n",
      "|Learning JavaScri...|     Addy Osmani|2012-07-01| O'Reilly Media|http://www.addyos...|\n",
      "+--------------------+----------------+----------+---------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read output csv file to dataframe\n",
    "\n",
    "books_csv_df = (\n",
    "    spark.read.format(\"csv\")\n",
    "    .option(\"header\",True)\n",
    "    .load(\"/home/manny/dev/cscie-63/hw02/output/part-00000-00b8b13a-3a33-4866-aa49-4538400795d4-c000.csv\")\n",
    ")\n",
    "\n",
    "books_csv_df.printSchema()\n",
    "\n",
    "books_csv_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- author: string (nullable = true)\n",
      " |-- published: date (nullable = true)\n",
      " |-- publisher: string (nullable = true)\n",
      " |-- website: string (nullable = true)\n",
      "\n",
      "+--------------------+----------------+----------+---------------+--------------------+\n",
      "|               title|          author| published|      publisher|             website|\n",
      "+--------------------+----------------+----------+---------------+--------------------+\n",
      "|Eloquent JavaScri...|Marijn Haverbeke|2014-12-14|No Starch Press|http://eloquentja...|\n",
      "|Learning JavaScri...|     Addy Osmani|2012-07-01| O'Reilly Media|http://www.addyos...|\n",
      "+--------------------+----------------+----------+---------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read from parquet output\n",
    "\n",
    "books_parq_df = (\n",
    "    spark.read.format(\"parquet\")\n",
    "    .option(\"header\",True)\n",
    "    .load(\"/home/manny/dev/cscie-63/hw02/outputII/part-00000-b8f24d25-d063-4fb3-adea-c701a6d88147-c000.snappy.parquet\")\n",
    ")\n",
    "\n",
    "books_parq_df.printSchema()\n",
    "\n",
    "books_parq_df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cee759d8ba3d05fbc0ce9d562811c528771065e3ebcaa60876c1a7482c086180"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
